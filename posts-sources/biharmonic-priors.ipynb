{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous post, I described a procedure for sampling from probability distributions using Monte Carlo methods.\n",
    "One of the subtle points that I tried to address there is what happens when the quantity we want to sample is a function of space and time.\n",
    "For example, we might want to infer the conductivity of an aquifer from well head measurements; the material density in the earth's subsurface from satellite gravimetry; or basal drag between a glacier and the landscape from measurements of its surface velocity.\n",
    "The parameter space is now a space of functions, and so it has infinitely many dimensions.\n",
    "Extending common algorithms to work in function spaces is hard.\n",
    "\n",
    "Since writing that first post, I read [this paper](https://doi.org/10.1214/13-STS421) by Cotter and others.\n",
    "I think my previous post was wrong now.\n",
    "Here I'd like to explain why (it involves Weyl's law) and how to fix it (it involves Nitsche's method).\n",
    "\n",
    "The failure, I think, is trying to straightforwardly bolt a statistical interpretation onto deterministic inverse problems.\n",
    "I'm guilty of this but I would argue that many textbooks on inverse problems are too.\n",
    "A common misstep is to assume that the common choices of regularization functional used in the deterministic inverse problems literature are going to translate into sensible prior distributions.\n",
    "They don't.\n",
    "\n",
    "To clarify the notation for later, we're interested in inferring a field $q$.\n",
    "In a deterministic inverse problem, we would add a multiple of a functional $R(q)$ to the objective in order to regularize the problem.\n",
    "The conventional approach is to use a multiple of\n",
    "$$R(q) = \\frac{1}{2}\\int_\\Omega|\\nabla q|^2dx.$$\n",
    "When we try to turn this into a Bayesian inference problem, we want a probability distribution $\\rho$ -- the prior -- such that\n",
    "$$-\\ln \\rho(q) \\propto R(q) + \\ldots$$\n",
    "The ellipses denote (in the quantum mechanic's parlance) another infinite constant that we can set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "Our goal is to construct a procedure for sampling from a probability distribution $\\pi(q)$.\n",
    "We assume that the parameters $q$ live in a separable Hilbert space $H$.\n",
    "When $H$ is infinite-dimensional, there are a couple of hard parts that don't occur in finite dimensions.\n",
    "\n",
    "For the rest of this post, we'll be concerned exclusively with the case where $\\pi$ is a Gaussian measure.\n",
    "In future posts we'll look at what happens when it isn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper priors\n",
    "\n",
    "In the deterministic inverse problems literature, it's common to use\n",
    "$$R(q) = \\frac{1}{2}\\int_\\Omega|\\nabla q|^2dx$$\n",
    "as a regularization functional.\n",
    "This accomplishes several goals.\n",
    "First, the inferred parameters obtained without regularization usually have spurious high-wavenumber noise.\n",
    "Adding this penalty filters out the noise.\n",
    "Second, it can guarantee a unique solution where the problem would be otherwise ill-posed.\n",
    "\n",
    "If we try to form a Gaussian measure $\\rho$ for which $-\\ln\\rho \\propto R(q) + \\ldots$, we'll run aground right away.\n",
    "Unless we also add boundary conditions to $q$, there is no constraint on the average value of $q$.\n",
    "We can add any constant we want to $q$ and the value of $R$ is unchanged.\n",
    "Viewing this in a probabilistic light now, the putative prior distribution doesn't integrate to 1 -- it is *improprer*.\n",
    "\n",
    "Strictly speaking, you can use an improper prior so long as the posterior is proper.\n",
    "The observational data need to provide enough of a constraint on the constant mode and this happens often.\n",
    "\n",
    "The justification for using an improper prior is when we have no information at all about what value the parameter in question can take, but we expect that the data can give it to us.\n",
    "Do we have no prior information whatsoever about the average value of the parameters we want to infer?\n",
    "Let's take the example I mentioned above about inferring the density of material within the earth from satellite observations of earth's gravitational pull.\n",
    "If you want priors, go weigh a rock, then put it in a beaker of water to measure its volume.\n",
    "I'll save you the trouble, it's probably got a density around 3000 kg/m${}^3$.\n",
    "Suppose you didn't know that Earth's core is solid iron.\n",
    "If you guessed that the range went from 300 to 30,000 kg/m${}^3$, you wouldn't be doing particularly good but it wouldn't be a terrible guess either.\n",
    "So it beggars belief that we should use a prior for a geophysical inverse problem that is totally uninformative about the mean value.\n",
    "It might have very high variance but certainly not infinite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace class operators\n",
    "\n",
    "To prescribe a Gaussian measure, we need to know its mean and covariance.\n",
    "The covariance has to be symmetric and positive-definite.\n",
    "(You can phrase my objection about properness above into questions about the nature of the covariance.)\n",
    "But in the function space setting, there are other criteria.\n",
    "We don't think about them in finite dimensions because they're almost vacuously true.\n",
    "But in the infinite-dimensional case they require much more thought.\n",
    "\n",
    "The first criterion is that the sum of all the eigenvalues of the covariance operator, i.e. the trace, is finite.\n",
    "In finite dimensions this is obvious.\n",
    "In function spaces, the property of being a trace class operator is very special.\n",
    "For example, the identity operator or any unitary map is not of trace class.\n",
    "\n",
    "Suppose that we wanted to make the most minimal adaptation of a determinstic inverse problem into a statistical one.\n",
    "Rather than use the improprer prior I showed above, we instead use\n",
    "$$R(q) = \\frac{1}{2}\\int_\\Omega\\left(q^2 + \\alpha^2|\\nabla q|^2\\right)dx$$\n",
    "where $\\alpha$ is some length scale we have to choose.\n",
    "If we define the operator\n",
    "$$L = I - \\alpha^2\\Delta,$$\n",
    "then $R(q) = \\frac{1}{2}\\langle Lq, q\\rangle$.\n",
    "In other words, $L$ is the precision -- the inverse of the covariance operator.\n",
    "Is $L^{-1}$ of trace class?\n",
    "\n",
    "We can answer that question using Weyl's law.\n",
    "But I want to be careful here about the units.\n",
    "I'll adopt a slightly different convention and say that $\\lambda$, $\\phi$ are an eigenvalue / eigenfunction pair for $-\\Delta$ if\n",
    "$$-\\Delta\\phi = \\lambda^{-2}\\phi.$$\n",
    "This choice, instead of the more conventional one, makes $\\lambda$ have units of length.\n",
    "Weyl's law then implies that the eigenvalues decay like\n",
    "$$\\lambda_n \\sim \\text{const}\\times\\text{vol}(\\Omega)^{1/d}\\times n^{-1/d}.$$\n",
    "So the eigenvalues of $(I - \\alpha^2\\Delta)^{-1}$ go like\n",
    "$$\\sigma_n = (1 + \\alpha^2\\lambda_n^{-2})^{-1} \\sim \\text{const}\\times\\frac{\\alpha^2}{\\text{vol}(\\Omega)^{2/d}} \\times n^{-2/d}.$$\n",
    "In dimension $d = 2$ the eigenvalues decay like $n^{-1}$.\n",
    "The trace diverges like the harmonic series!\n",
    "\n",
    "Suppose we instead take the precision to have the biharmonic operator as the leading term:\n",
    "$$L = I - \\alpha_1^2\\Delta + \\alpha_2^2\\Delta^2$$\n",
    "where now we need to pick two length scales $\\alpha_1$, $\\alpha_2$.\n",
    "Then Weyl's law now comes to the rescue to show that the eigenvalues of $L^{-1}$ are instead asymptotic to\n",
    "$$\\sigma_n \\sim \\text{const} \\times n^{-4/d}$$\n",
    "which is summable in dimensions 2 and 3.\n",
    "\n",
    "Further down, I'll show some samples generated from both the wrong $I - \\alpha^2\\Delta$ prior and the biharmonic prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposal mechanism\n",
    "\n",
    "Questions about what kinds of covariance operator to choose concern the problem that we wish to solve.\n",
    "The final challenge I ran into is not about what problem to solve but how to solve it.\n",
    "A common thread in the advanced MCMC sampling literature is to use a Langevin-type equation to generate samples:\n",
    "$$\\dot q = -\\frac{1}{2}G^{-1}\\nabla\\log\\pi + G^{-1/2}\\dot W$$\n",
    "where $G$ is some s.p.d. linear operator.\n",
    "We can then discretize this ODE using the scheme of our choice.\n",
    "In fact, there is only one correct choice of scheme in the function space setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "Now let's write some code to try and put this into practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import assemble\n",
    "from firedrake.petsc import PETSc\n",
    "\n",
    "area = assemble(Constant(1) * dx(mesh))\n",
    "\n",
    "class NoiseGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        function_space,\n",
    "        covariance=None,\n",
    "        generator=random.default_rng()\n",
    "    ):\n",
    "        if covariance is None:\n",
    "            ϕ = firedrake.TrialFunction(function_space)\n",
    "            ψ = firedrake.TestFunction(function_space)\n",
    "            covariance = inner(ϕ, ψ) * dx\n",
    "\n",
    "        M = assemble(covariance, mat_type='aij').M.handle\n",
    "        ksp = PETSc.KSP().create()\n",
    "        ksp.setOperators(M)\n",
    "        ksp.setUp()\n",
    "\n",
    "        pc = ksp.pc\n",
    "        pc.setType(pc.Type.CHOLESKY)\n",
    "        pc.setFactorSolverType(PETSc.Mat.SolverType.PETSC)\n",
    "        pc.setFactorSetUpSolverType()\n",
    "        L = pc.getFactorMatrix()\n",
    "        pc.setUp()\n",
    "\n",
    "        self.rng = generator\n",
    "        self.function_space = function_space\n",
    "        self.preconditioner = pc\n",
    "        self.cholesky_factor = L\n",
    "\n",
    "        self.rhs = firedrake.Function(self.function_space)\n",
    "        self.noise = firedrake.Function(self.function_space)\n",
    "\n",
    "    def __call__(self):\n",
    "        z, ξ = self.rhs, self.noise\n",
    "        N = len(z.dat.data_ro[:])\n",
    "        z.dat.data[:] = self.rng.standard_normal(N)\n",
    "\n",
    "        L = self.cholesky_factor\n",
    "        with z.dat.vec_ro as Z:\n",
    "            with ξ.dat.vec as Ξ:\n",
    "                L.solveBackward(Z, Ξ)\n",
    "                Ξ *= np.sqrt(area / N)\n",
    "\n",
    "        return ξ.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The biharmonic operator\n",
    "\n",
    "Here we'd like to use the functional\n",
    "$$R(q) = \\int_\\Omega\\left(q^2 + \\lambda^2|D^2q|^2\\right)dx$$\n",
    "which penalizes large values of the curvature $D^2q$.\n",
    "Conventional finite element basis functions are continuous and piecewise-differentiable, but their derivatives have jump discontinuities across cell boundaries.\n",
    "There are continuously-differentiable finite element bases which we could use to construct a conforming discretization of the curvature penalty.\n",
    "I'll instead use a non-conforming discretization based on ordinary CG elements.\n",
    "This approach is similar to how we used DG elements for the convection-diffusion equation.\n",
    "For that problem, we applied Nitsche's method at all of the cell boundaries in order to make the solution continuous.\n",
    "Here we'll instead apply Nitsche's method at all the cell boundaries to make the solution's gradient continuous.\n",
    "I'm partly following [this paper](https://doi.org/10.1515/jnma-2023-0028) for discretization of the curvature penalty but working back to a minimization form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import avg, jump, outer, dS\n",
    "firedrake.adjoint.continue_annotation()\n",
    "\n",
    "ϕ = firedrake.Function(Q)\n",
    "\n",
    "λ = firedrake.Constant(1.0)\n",
    "Dϕ = grad(ϕ)\n",
    "DDϕ = grad(Dϕ)\n",
    "\n",
    "h = firedrake.FacetArea(mesh)\n",
    "vol = firedrake.CellVolume(mesh)\n",
    "\n",
    "α = firedrake.Constant(4.0)\n",
    "k = firedrake.Constant(Q.ufl_element().degree())\n",
    "β = 3 * α * k * (k - 1) / 8 * avg(h)**2 * avg(1 / vol)\n",
    "β_Γ = 3 * α * k * (k - 1) * h**2 / vol\n",
    "\n",
    "ν = firedrake.FacetNormal(mesh)\n",
    "J_cells = inner(DDϕ, DDϕ) * dx\n",
    "J_facets = avg(inner(DDϕ, outer(ν, ν))) * jump(Dϕ, ν) * dS\n",
    "J_facet_penalty = β / avg(h) * jump(Dϕ, ν)**2 * dS\n",
    "J_boundary = inner(Dϕ, ν) * inner(DDϕ, outer(ν, ν)) * ds\n",
    "J_boundary_penalty = β_Γ / h * inner(Dϕ, ν)**2 * ds\n",
    "\n",
    "J_Δ = 0.5 * (J_cells - J_facets - J_boundary + J_facet_penalty + J_boundary_penalty)\n",
    "J_2 = 0.5 * ϕ**2 * dx\n",
    "\n",
    "J = J_2 + λ ** 4 * J_Δ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import derivative\n",
    "\n",
    "M = derivative(derivative(J, ϕ), ϕ)\n",
    "biharmonic_generator = NoiseGenerator(\n",
    "    function_space=Q,\n",
    "    covariance=M,\n",
    "    generator=np.random.default_rng(seed=1729),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows a single random sample generated from the prior distribution.\n",
    "This stochastic process has been used as an approximate model for the topography of real landscapes and perhaps you can see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = biharmonic_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firedrake.trisurf(z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the proposal is generated by numerically integrating the SDE\n",
    "$$\\dot q = -\\frac{1}{2}M^{-1}dJ(q) + M^{-\\frac{1}{2}}\\dot B.$$\n",
    "We then accept or reject the proposal using the usual Metropolis criterion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "firedrake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nikola": {
   "category": "",
   "date": "2025-04-06 13:17:30 UTC-07:00",
   "description": "",
   "link": "",
   "slug": "biharmonic-priors",
   "tags": "",
   "title": "Biharmonic priors",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
